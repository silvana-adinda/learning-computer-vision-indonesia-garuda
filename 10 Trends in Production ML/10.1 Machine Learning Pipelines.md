# Machine Learning Pipelines

## The Need for Pipelines

Dalam pengembangan model machine learning (ML), seringkali kita menghadapi tantangan dalam mengelola alur kerja yang kompleks. Alur kerja ini mencakup berbagai tahapan seperti pra-pemrosesan data, pelatihan model, evaluasi, dan deployment. **Machine Learning Pipelines** adalah solusi untuk mengotomatisasi dan mengelola alur kerja ini secara efisien. Pipelines memungkinkan kita untuk mengotomatisasi langkah-langkah tersebut, memastikan konsistensi, dan memudahkan reproduksi hasil [1].

Pipelines juga membantu dalam mengelola dependensi antara berbagai tahapan. Misalnya, tahap pra-pemrosesan data harus selesai sebelum tahap pelatihan model dimulai. Dengan menggunakan pipelines, kita dapat memastikan bahwa setiap tahap dijalankan dalam urutan yang benar dan hanya dijalankan jika diperlukan.

## Kubeflow Pipelines Cluster

**Kubeflow Pipelines** adalah salah satu alat yang populer untuk membangun dan mengelola ML pipelines. Kubeflow adalah platform open-source yang dirancang untuk menjalankan alur kerja ML pada Kubernetes. Kubeflow Pipelines memungkinkan kita untuk mendefinisikan, menjalankan, dan memantau alur kerja ML yang kompleks [2].

Kubeflow Pipelines menyediakan antarmuka grafis untuk memvisualisasikan alur kerja, memudahkan debugging, dan melacak eksperimen. Selain itu, Kubeflow Pipelines juga mendukung integrasi dengan berbagai alat ML seperti TensorFlow, PyTorch, dan lainnya.

### Containerizing the Codebase

Sebelum membangun pipeline, langkah pertama adalah meng-containerize kode kita. **Containerization** adalah proses mengemas aplikasi beserta semua dependensinya ke dalam sebuah container yang dapat dijalankan di mana saja. Docker adalah alat yang umum digunakan untuk containerization.

Dengan meng-containerize kode, kita memastikan bahwa lingkungan eksekusi konsisten di seluruh tahap pipeline. Ini menghindari masalah yang sering terjadi karena perbedaan versi library atau dependensi.

Berikut adalah contoh Dockerfile untuk meng-containerize aplikasi ML:

```dockerfile
# Dockerfile
FROM python:3.8-slim

# Install dependencies
COPY requirements.txt .
RUN pip install -r requirements.txt

# Copy the application code
COPY . /app
WORKDIR /app

# Set the entry point
ENTRYPOINT ["python", "train.py"]
```

Dalam contoh di atas, kita menggunakan image Python 3.8, menginstal dependensi dari requirements.txt, dan menyalin kode aplikasi ke dalam container.

## Writing a Component

Dalam Kubeflow Pipelines, setiap tahap dalam pipeline disebut sebagai komponen. Komponen adalah unit kerja yang independen dan dapat dijalankan dalam container. Setiap komponen memiliki input dan output yang jelas, sehingga dapat dihubungkan dengan komponen lain dalam pipeline.

Berikut adalah contoh komponen sederhana untuk pra-pemrosesan data:

```python
# preprocess.py
import pandas as pd
from sklearn.model_selection import train_test_split

def preprocess_data(input_path: str, output_path: str):
    # Load data
    data = pd.read_csv(input_path)
    
    # Perform preprocessing
    data = data.dropna()
    data = pd.get_dummies(data, drop_first=True)
    
    # Split data into train and test sets
    train, test = train_test_split(data, test_size=0.2)
    
    # Save processed data
    train.to_csv(f"{output_path}/train.csv", index=False)
    test.to_csv(f"{output_path}/test.csv", index=False)

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--input_path", type=str, required=True)
    parser.add_argument("--output_path", type=str, required=True)
    args = parser.parse_args()
    
    preprocess_data(args.input_path, args.output_path)
```

Komponen ini dapat dijalankan dalam container dan akan menghasilkan file CSV yang telah diproses.

## Connecting Components

Setelah kita memiliki beberapa komponen, langkah selanjutnya adalah menghubungkannya dalam sebuah pipeline. Kubeflow Pipelines menggunakan Directed Acyclic Graph (DAG) untuk mendefinisikan alur kerja. Setiap komponen dihubungkan berdasarkan dependensinya.

Berikut adalah contoh pipeline yang menghubungkan komponen pra-pemrosesan data dan pelatihan model:

```python
# pipeline.py
import kfp
from kfp import dsl

@dsl.component
def preprocess_data(input_path: str, output_path: str):
    # Komponen pra-pemrosesan data
    ...

@dsl.component
def train_model(train_path: str, model_path: str):
    # Komponen pelatihan model
    ...

@dsl.pipeline(
    name="ML Pipeline",
    description="A simple ML pipeline for preprocessing and training."
)
def ml_pipeline(input_path: str, output_path: str, model_path: str):
    preprocess_task = preprocess_data(input_path=input_path, output_path=output_path)
    train_task = train_model(train_path=preprocess_task.output, model_path=model_path)

if __name__ == "__main__":
    kfp.compiler.Compiler().compile(ml_pipeline, "ml_pipeline.yaml")
```

Dalam contoh di atas, komponen preprocess_data dan train_model dihubungkan sehingga output dari pra-pemrosesan data digunakan sebagai input untuk pelatihan model.

## Automating a Run

Setelah pipeline didefinisikan, kita dapat mengotomatisasi eksekusinya. Kubeflow Pipelines menyediakan fitur untuk menjalankan pipeline secara otomatis berdasarkan trigger tertentu, seperti perubahan data atau jadwal waktu.

Berikut adalah contoh menjalankan pipeline menggunakan CLI Kubeflow:

```bash
kfp run submit -e <experiment-id> -r <run-name> -f ml_pipeline.yaml
```

Dengan mengotomatisasi pipeline, kita dapat memastikan bahwa model selalu diperbarui dengan data terbaru tanpa intervensi manual.

## Referensi
1. M. Zaharia et al., "MLflow: A Platform for ML Development and Productionization," in Proceedings of the 2018 USENIX Conference on Operational Machine Learning, 2018.
2. J. Dean and S. Ghemawat, "MapReduce: Simplified Data Processing on Large Clusters," in Communications of the ACM, 2008.


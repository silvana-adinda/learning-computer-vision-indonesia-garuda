# Distribution Strategy pada Machine Learning

## Memilih Strategi Distribusi

Dalam Machine Learning terutama pada model Computer Vision, terdapat tiga strategi utama untuk distribusi pelatihan model:

1. **MirroredStrategy**
   - Menggandakan struktur model ke setiap GPU yang tersedia.
   - Setiap bobot dalam model disinkronkan di seluruh replika.
   - Cocok digunakan pada satu mesin dengan satu atau beberapa GPU.

2. **MultiWorkerMirroredStrategy**
   - Memperluas konsep **MirroredStrategy** ke GPU yang tersebar di beberapa mesin.
   - Mengharuskan konfigurasi variabel lingkungan `TF_CONFIG` untuk mengelola komunikasi antar pekerja.
   - Disarankan menggunakan layanan cloud publik seperti **Vertex AI**.

3. **TPUStrategy**
   - Menjalankan pelatihan pada TPU (Tensor Processing Unit), yang dirancang khusus untuk tugas pembelajaran mesin.
   - TPU mendapatkan peningkatan kecepatan melalui unit perkalian matriks khusus dan jaringan komunikasi berkecepatan tinggi.
   - Hanya tersedia di **Google Cloud Platform**.

Ketiga strategi ini menggunakan pendekatan **data parallelism**, di mana setiap batch data dibagi ke beberapa pekerja sebelum dilakukan operasi all-reduce【1】.

## Membuat Strategi Distribusi

Kode berikut menunjukkan bagaimana cara membuat dan menggunakan strategi distribusi dalam **TensorFlow**:

```python
import tensorflow as tf

# Menggunakan MirroredStrategy
strategy = tf.distribute.MirroredStrategy()

with strategy.scope():
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
```

Jika menggunakan **MultiWorkerMirroredStrategy**, perlu memastikan variabel `TF_CONFIG` dikonfigurasi dengan benar:

```python
import json, os

os.environ["TF_CONFIG"] = json.dumps({
    "cluster": {
        "worker": ["worker0.example.com:2222", "worker1.example.com:2222"]
    },
    "task": {"type": "worker", "index": 0}
})

strategy = tf.distribute.MultiWorkerMirroredStrategy()
```

Untuk **TPUStrategy**, dapat digunakan kode berikut:

```python
tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()
strategy = tf.distribute.TPUStrategy(tpu)
```

## Optimalisasi dan Implementasi

- **Shuffling Data**: Pastikan data diacak sebelum didistribusikan ke beberapa pekerja.
- **Virtual Epochs**: Mengatur jumlah contoh pelatihan tetap untuk memastikan stabilitas pelatihan【2】.
- **Optimasi TPU**: Mengatur `steps_per_execution` agar beberapa batch dikirim sekaligus guna mengurangi overhead komunikasi.

```python
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'], steps_per_execution=32)
```

## Kesimpulan

Memilih strategi distribusi yang tepat bergantung pada infrastruktur yang tersedia dan kompleksitas model. Jika hanya menggunakan satu mesin dengan beberapa GPU, **MirroredStrategy** adalah pilihan terbaik. Jika menggunakan beberapa mesin, **MultiWorkerMirroredStrategy** diperlukan. Sementara itu, **TPUStrategy** memberikan keunggulan dalam performa pada cloud computing seperti **Google Cloud**.

---
**Referensi**
1. Practical Machine Learning for Computer Vision, Valliappa Lakshmanan, Martin Görner, 2021.
2. TensorFlow Documentation: https://www.tensorflow.org/guide/distributed_training
